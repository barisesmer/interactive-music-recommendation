{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import det, inv\n",
    "from scipy.special import digamma\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.875, 4.75 , 4.5  , 4.   , 3.   , 1.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 5.   , 1.   ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map time 't' to a vector. The epsilon below is the one from the paper\n",
    "def vectorize(t, epsilon):\n",
    "#     print(t)\n",
    "#     print(epsilon.shape)\n",
    "    v = np.concatenate([t - epsilon, [t,1]])\n",
    "    v[np.where(v < 0)] = 0\n",
    "    \n",
    "    return v\n",
    "\n",
    "epsilon = np.array([np.power(2,i) for i in np.arange(-3,12,dtype=float)])\n",
    "vectorize(5, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quantile(x,t,x_mean_coeff, x_var_coeff, t_mean_coeff, t_var_coeff, alpha, num_samples):\n",
    "    # sample from theta.T.dot(x) and beta.T.dot(x) and create histogram\n",
    "    samples_1 = np.random.normal(x.T.dot(x_mean_coeff).item(), x.T.dot(x_var_coeff).dot(x).item(), size = num_samples)\n",
    "    samples_2 = np.random.normal(t.T.dot(t_mean_coeff).item(), t.T.dot(t_var_coeff).dot(t).item(), size = num_samples)\n",
    "    \n",
    "    final_samples = samples_1*samples_2\n",
    "    \n",
    "    # construct histogram\n",
    "    pdf, intervals = np.histogram(final_samples, 100)\n",
    "    cdf = np.cumsum(pdf/sum(pdf))\n",
    "    \n",
    "    # return quantile \n",
    "    for index, value in enumerate(cdf):\n",
    "        if value >= alpha:\n",
    "            return intervals[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes_UCB_V:\n",
    "    def __init__(self, x, t, r):\n",
    "        self.THRESHOLD = 10e-3\n",
    "        self.x = x # features of songs - dim : num_of_features x num_of_songs\n",
    "        self.t = t # last listened times of songs - dim : (num_of_intervals + 2) x num_of_songs\n",
    "        self.r = r # ratings - dim : 1 x num_of_songs\n",
    "        self.p,self.N = x.shape\n",
    "        self.K = t.shape[0]\n",
    "        # TODO: How to initialize these variables?\n",
    "        self.lambda_theta_N = np.identity(self.p)\n",
    "        self.eta_theta_N = np.zeros((self.p,1))\n",
    "        self.eta_beta_N = np.zeros((self.K,1))\n",
    "        self.lambda_beta_N = np.identity(self.K)\n",
    "        self.D_0 = np.identity(self.p)\n",
    "        self.E_0 = np.identity(self.K)\n",
    "        self.mu_theta_0 = np.zeros((self.p,1))\n",
    "        self.mu_beta_0 = np.zeros((self.K,1))\n",
    "        self.a_0 = 2\n",
    "        self.b_0 = 2 * 10e-8\n",
    "        self.a_N = self.a_0\n",
    "        self.b_N = self.b_0\n",
    "        self.prev_L = 0.0\n",
    "\n",
    "        \n",
    "    def optimize_parameters(self):\n",
    "        while self.is_converged(self.lower_bound()) == False:\n",
    "            self.update_theta()\n",
    "            self.update_beta()\n",
    "            self.update_tau()\n",
    "        return self.lambda_theta_N, self.eta_theta_N, self.lambda_beta_N, self.eta_beta_N\n",
    "    \n",
    "    def lower_bound(self):       \n",
    "        return (self.a_0 * np.log(self.b_0) \n",
    "            + (self.a_0 - 1) * (digamma(self.a_N) - np.log(self.b_N))\n",
    "            - (self.b_0 * self.a_N / self.b_N)\n",
    "            - (np.log(2 * np.pi)/2)\n",
    "            - ( np.log(det(self.D_0))/2 )\n",
    "            + (self.p / 2) * (digamma(self.a_N) - np.log(self.b_N))\n",
    "            - (self.a_N / (2 * self.b_N)) * (np.trace(self.D_0.dot(inv(self.lambda_theta_N))) \n",
    "                                               + (self.mu_theta_0 - self.expected_theta()).T.dot(inv(self.D_0)).dot(self.mu_theta_0 - self.expected_theta())\n",
    "                                             )\n",
    "            - (self.K * np.log(2 * np.pi) / 2)\n",
    "            - (np.log(det(self.E_0)) / 2)\n",
    "            + (self.K / 2) * (digamma(self.a_N) - np.log(self.b_N))\n",
    "            - (self.a_N / (2 * self.b_N)) * (np.trace(self.E_0.dot(inv(self.lambda_beta_N))) \n",
    "                                               + (self.mu_theta_0 - self.expected_theta()).T.dot(inv(self.D_0)).dot(self.mu_theta_0 - self.expected_theta())\n",
    "                                             )\n",
    "            - (np.log(2 * np.pi)/ 2)\n",
    "            + (1 / 2) * (digamma(self.a_N) - np.log(self.b_N))\n",
    "            - (self.a_N / (2 * self.b_N)) * self.sum1() # Check\n",
    "            + (self.a_N / self.b_N) * self.sum2() # Check\n",
    "            + (self.K / 2) * (1 + np.log(2 * np.pi))\n",
    "            + (1 / 2) * (np.log(det(inv(self.lambda_beta_N))))\n",
    "            + (self.p / 2) * (1 + np.log(2 * np.pi))\n",
    "            + (1 / 2) * (np.log(det(inv(self.lambda_theta_N))))\n",
    "            - (self.a_N - 1) * digamma(self.a_N)\n",
    "            - np.log(self.b_N) + self.a_N        \n",
    "            )        \n",
    "                       \n",
    "    def sum1(self):\n",
    "        result = self.r.dot(self.r.T)\n",
    "\n",
    "        for i in range(self.N):\n",
    "            x_i = self.x[:,i].reshape((self.p,1))\n",
    "            t_i = self.t[:,i].reshape((self.K,1))\n",
    "            \n",
    "            result += x_i.T.dot(self.expected_outer_theta()).dot(x_i).dot(t_i.T).dot(self.expected_outer_beta()).dot(t_i)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def sum2(self):\n",
    "        result = 0\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            x_i = self.x[:,i].reshape((self.p,1))\n",
    "            t_i = self.t[:,i].reshape((self.K,1))\n",
    "            \n",
    "            r_i = self.r[0][i]\n",
    "            \n",
    "            result += r_i*(x_i.T.dot(self.expected_theta()).dot(t_i.T).dot(self.expected_beta())) + self.b_0\n",
    "            \n",
    "        return result\n",
    "                       \n",
    "    def is_converged(self, L):\n",
    "        if abs(L - self.prev_L) < self.THRESHOLD:\n",
    "            return True\n",
    "        else:\n",
    "            self.prev_L = L\n",
    "            return False\n",
    "    \n",
    "    def sum_product_along_axis_1(self, First, Second, Beta):\n",
    "        p,N = First.shape\n",
    "        K = Second.shape[0]\n",
    "\n",
    "        result = np.zeros((p,p))\n",
    "        \n",
    "        for i in range(N):\n",
    "            f_i = First[:,i].reshape((p,1))\n",
    "            s_i = Second[:,i].reshape((K,1))\n",
    "            \n",
    "            result += f_i.dot(s_i.T).dot(Beta).dot(s_i).dot(f_i.T)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def sum_product_along_axis_2(self, v_1, First, Second, v_2):\n",
    "        p,N = First.shape\n",
    "        K = Second.shape[0]\n",
    "\n",
    "        result = np.zeros((p,1))\n",
    "        \n",
    "        for i in range(N):\n",
    "            f_i = First[:,i].reshape((p,1))\n",
    "            s_i = Second[:,i].reshape((K,1))\n",
    "            r_i = v_1[0][i]\n",
    "            \n",
    "            result += ( r_i * (f_i.dot(s_i.T).dot(v_2)) )\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def update_theta(self):\n",
    "        exp_tau = self.expected_tau()\n",
    "        \n",
    "        self.lambda_theta_N = exp_tau * (inv(self.D_0) + self.sum_product_along_axis_1(self.x, self.t, self.expected_outer_beta()))\n",
    "\n",
    "        self.eta_theta_N = exp_tau * (inv(self.D_0).dot(self.mu_theta_0)  + self.sum_product_along_axis_2(self.r, self.x, self.t, self.expected_beta()))\n",
    "\n",
    "    def update_beta(self):               \n",
    "        exp_tau = self.expected_tau()\n",
    "        E_0_inv = inv(self.E_0)\n",
    "\n",
    "        self.lambda_beta_N = exp_tau * (E_0_inv + self.sum_product_along_axis_1(self.t, self.x, self.expected_outer_theta()))              \n",
    "        \n",
    "        self.eta_beta_N = exp_tau * ( E_0_inv.dot(self.mu_beta_0) + self.sum_product_along_axis_2(self.r, self.t, self.x, self.expected_theta()))\n",
    "\n",
    "    def update_tau(self):\n",
    "        self.a_N = (self.p + self.K + self.N) / 2 + self.a_0\n",
    "        b_N_update = 0.5*(np.trace(inv(self.D_0).dot(self.expected_outer_theta())) + (self.mu_theta_0.T - 2*self.expected_theta().T).dot(inv(self.D_0)).dot(self.mu_theta_0))\n",
    "\n",
    "        b_N_update += 0.5*(np.trace(inv(self.E_0).dot(self.expected_outer_beta())) + (self.mu_beta_0.T - 2*self.expected_beta().T).dot(inv(self.E_0)).dot(self.mu_beta_0))\n",
    "        \n",
    "        b_N_update += (0.5*self.sum1() - self.sum2() + self.b_0)\n",
    "        \n",
    "        self.b_N = b_N_update\n",
    "\n",
    "    def expected_beta(self):\n",
    "        return inv(self.lambda_beta_N).dot(self.eta_beta_N)\n",
    "    \n",
    "    def expected_theta(self):\n",
    "        return inv(self.lambda_theta_N).dot(self.eta_theta_N)\n",
    "    \n",
    "    def expected_tau(self):\n",
    "        return self.a_N / self.b_N\n",
    "    \n",
    "    def expected_outer_beta(self):\n",
    "        exp_beta = self.expected_beta()\n",
    "        return inv(self.lambda_beta_N) + exp_beta.dot(exp_beta.T)\n",
    "    \n",
    "    def expected_outer_theta(self):\n",
    "        exp_theta = self.expected_theta()\n",
    "        return inv(self.lambda_theta_N) + exp_theta.dot(exp_theta.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = np.array([np.power(2,i) for i in np.arange(-3,12,dtype=float)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesUCB:\n",
    "    \n",
    "    def __init__(self, simulation=True): \n",
    "        self.epsilon = epsilon\n",
    "        self.recommended_song_ids = []\n",
    "        self.simulation = simulation\n",
    "        self.recommend_song()\n",
    "        \n",
    "        \n",
    "    def get_last_song_id():\n",
    "        return self.recommended_song_ids[-1]\n",
    "    \n",
    "    \n",
    "    def recommend_song(self):\n",
    "        if len(self.recommended_song_ids) == 0:\n",
    "            song_id = np.random.randint(num_songs)\n",
    "        else:\n",
    "            song_id = self.recommended_song_candidate\n",
    "        self.recommended_song_ids.append(song_id)\n",
    "        recommend_song(song_id, self.simulation)\n",
    "        print(str(song_id) + ' ' + song_names[song_id])\n",
    "\n",
    "        \n",
    "    def feedback(self,rating):\n",
    "        rate_song(rating)\n",
    "        t = get_history_times()\n",
    "        x = get_history_features()\n",
    "        y = get_ratings()\n",
    "        self.recommended_song_candidate = self.driver(x, t, y, epsilon)\n",
    "        self.recommend_song()\n",
    "        \n",
    "        \n",
    "    def driver(self, features, last_listened, ratings, epsilon):\n",
    "        time_vectors = np.zeros((len(last_listened),len(epsilon) + 2))\n",
    "        for i, x in enumerate(last_listened):\n",
    "            time_vectors[i,:] = vectorize(x, epsilon)\n",
    "\n",
    "        time_vectors = time_vectors.T\n",
    "\n",
    "        ratings = ratings.reshape((1,len(ratings)))\n",
    "\n",
    "        bayesUCB_V = Bayes_UCB_V(features, time_vectors, ratings)\n",
    "\n",
    "        lambda_theta_N, eta_theta_N, lambda_beta_N, eta_beta_N = bayesUCB_V.optimize_parameters()\n",
    "\n",
    "        # section 4.2.3 : page 11\n",
    "        x_mean_coeff = inv(lambda_theta_N).dot(eta_theta_N)\n",
    "        x_var_coeff = inv(lambda_theta_N)\n",
    "\n",
    "        t_mean_coeff = inv(lambda_beta_N).dot(eta_beta_N)\n",
    "        t_var_coeff = inv(lambda_beta_N)\n",
    "\n",
    "        # get quantiles for each song and choose argmax\n",
    "        N = features.shape[1]\n",
    "        quantiles = []\n",
    "        for i in range(N):\n",
    "            x_i = features[:,i].reshape((features.shape[0],1))\n",
    "            t_i = time_vectors[:,i].reshape((time_vectors.shape[0],1))\n",
    "\n",
    "            quantiles.append(calculate_quantile(x_i, t_i, x_mean_coeff, x_var_coeff, t_mean_coeff, t_var_coeff, 1 - 1/(N + 1), 10000))\n",
    "\n",
    "        return np.argmax(quantiles)\n",
    "    \n",
    "    \n",
    "    def optimization(self, params, *args):\n",
    "        x = args[0]\n",
    "        y = args[1]\n",
    "        t = args[2]\n",
    "        theta = params[:-1]\n",
    "        s = params[-1]\n",
    "        y_model = theta.T.dot(x)*(1 - np.exp(-t/s))\n",
    "        error = y - y_model\n",
    "        return sum(error**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
