{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Greedy & ε-Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !! Incomplete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @TODO\n",
    "\n",
    "- use L_BFGS_B to chose new best song\n",
    "- update feature ratings at each step\n",
    "- combine with features of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest multiarmed bandit approach, namely epsilon-greedy, chooses the arm with the highest predicted pay off with probability 1−e or chooses arms uniformly at random with probability e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy:  The Greedy approach represents pure exploitation and always recommends the song with the highest predicted rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Therefore, the Greedy approach simulates the strategy used by the traditional recommenders. \n",
    "    \n",
    "For Greedy, minimum mean square error approach was used to estimate the parameters {θ,s}, which were optimized by the LBFGS-B algorithm [Byrd et al. 1995]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs as greedy if epsilon set to 0\n",
    "# parameters:\n",
    "# epsilon = random (non-greedy) choice probability, between [0-1]\n",
    "#\n",
    "class epsilonGreedy:\n",
    "    def __init__(self,epsilon,num_songs,expected_ratings): #expected_ratings = np.zeros(num_songs)\n",
    "        self.epsilon = epsilon\n",
    "        self.num_songs = num_songs\n",
    "        self.ratings = np.zeros(self.num_songs)\n",
    "        self.best_rating = max(self.ratings)\n",
    "        self.choices = np.zeros(self.num_songs)\n",
    "        self.expected_ratings = np.zeros(self.num_songs) \n",
    "        self.regret = 0 # total regret\n",
    "        self.regrets = [0] # history of regrets\n",
    "        self.t = 0\n",
    "        self.last_song_index = None\n",
    "        self.last_song_rating = None\n",
    "        \n",
    "    def get_rating(self):\n",
    "        pass\n",
    "        #self.last_song_rating = # get from user\n",
    "    def choose_song(self):\n",
    "        self.t+=1\n",
    "        if self.epsilon > np.random.rand():\n",
    "            return np.random.randint(self.num_songs)# random choice\n",
    "        else:\n",
    "            return np.argmax(self.expected_ratings)# greedy choice\n",
    "    \n",
    "    def update_regret(self):\n",
    "        self.regret += self.best_rating - self.ratings[self.selected_song_index]\n",
    "        self.regrets.append(self.regret)\n",
    "        \n",
    "    def update_expectation(self):\n",
    "        self.choices[self.selected_song_index]+=1\n",
    "        alpha = 1./self.choices[self.selected_song_index]\n",
    "        self.expected_ratings[self.selected_song_index]+=alpha * (self.selected_song_rating - self.expected_ratings[self.selected_song_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for poster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In greedy approach the song with maximum expected rating is used. Where expected rating is calculated from previous ratings of the user. Since there is no exploration in greedy approach all unlistened songs have expected rating of 0.\n",
    "\n",
    "Since our system initializes with no pre listened songs. Pure exploration can not be even initialized. To avoid this we have used ε-greedy approach. In which the recommended song is chosen randomly with probability ε (epsilon). This allows limited-random exploitation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/agilajah/multi-armed-bandit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
